Overall plan: implement a SQL database.

Some assumptions:
- I think I'll ditch the table heap, and instead use Btrees for primary row storage (by primary key, which will be required) and also for indexes.


- Implement database
  - Disk manager
    - Current goal: make it concurrent (currently requires one giant mutex)
      - Requires: support for `read_at` and `write_at` for `tokio::fs`
  - Buffer pool
    - Current goal: concurrent IO (currently holds buffer page lock on IO).
      - First, do it with separate mutex for disk manager
      - Once disk manager is actually concurrent, use it
  - B+tree
    - Current goal: write the operations as pseudocode, and see which operations will be needed on pages. Then implement them.
      - first without much regard for concurrency (recursively grab locks if needed), then rewrite to latch crabbing
    - page format is now unified for leaf and internal pages - update the docs 
  - Catalog
  - Query parser
  - Query execution
  - Query planner
  - WAL
  - Transactions

# Questions

## Should we have different formats for Btree internal and leaf pages?

Probably not. This would simplify things a lot.

Postgres, for example, has a single generic page format (which just stores N "tuples" - byte sequences) which it uses for heap, btree and also other things. I think we should do the same.

I wonder how Postgres stores child pointers, though.
-> "pivot tuples" (tuples in internal pages) have a downlink pointer (in place of the target tuple id)

Now I wonder how Postgres stores the last downlink pointer (after all pivot keys). Sentinel pivot?
-> on non-leaf pages, the first pivot key is assumed to be "minus infinity"
Interesting, I considered hacking on the last one. Maybe we should use the postgres convention though. So: downlink pointer is "after" the key in a pivot tuple.
